{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import streamlit as st\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_web_results(query, max_results=5):\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        # Check if results are empty or minimal!\n",
    "        if not results:\n",
    "            print(\"No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        # Print raw structure for debugging\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "    return [f\"{r['title']}: {r['body']} ({r['href']})\" for r in results]\n",
    "\n",
    "def build_context(query):\n",
    "    results = retrieve_web_results(query)\n",
    "    if not results:\n",
    "        return \"No relevant current web information was found.\"\n",
    "    return \"\\n\".join(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)  # Authenticate with Hugging Face hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aef451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,         \n",
    "    return_full_text=False,              # return_full_text=False,\n",
    "    max_new_tokens=1000\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bf558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_web_results(query, max_results=5):\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        # Check if results are empty or minimal!\n",
    "        if not results:\n",
    "            print(\"No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        # Print raw structure for debugging\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "    return [f\"{r['title']}: {r['body']} ({r['href']})\" for r in results]\n",
    "\n",
    "def build_context(query):\n",
    "    results = retrieve_web_results(query)\n",
    "    if not results:\n",
    "        return \"No relevant current web information was found.\"\n",
    "    return \"\\n\".join(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Example persona and question\n",
    "persona = \"shahrukh khan\"\n",
    "user_question = \"What is Nepal News Today?\"\n",
    "\n",
    "def build_persona_context(persona, user_question):\n",
    "    return build_context(user_question)  # DuckDuckGo web search for user's question\n",
    "\n",
    "def get_system_message(persona):\n",
    "    return (\n",
    "        \"You are Shah Rukh Khan, the iconic Bollywood superstar known as 'King Khan' and loved for your wit, charisma, and warmth.\\n\"\n",
    "        \"You always answer with confidence, a touch of poetic charm and kindness, and sometimes weave in your famous movie dialogues.\\n\"\n",
    "        \"Your style is friendly, clever, and respectful towards everyone—fans, journalists, and even your rivals.\\n\"\n",
    "        \"Whenever possible, deliver your answer with humor or heart, and don't hesitate to quote a famous line, like:\\n\"\n",
    "        \"\\\"Don ko pakadna mushkil hi nahin, namumkin hai!\\\"\\n\"\n",
    "        \"\\\"Picture abhi baaki hai mere dost!\\\"\\n\"\n",
    "        \"If you don't know something, admit it gracefully, maybe with a witty twist.\\n\"\n",
    "        \"ALWAYS ground your facts in the information provided in the context below (from web results). Do NOT make up details!\"\n",
    "    )\n",
    "\n",
    "context = build_persona_context(persona, user_question)\n",
    "system_message = get_system_message(persona)\n",
    "\n",
    "# LangChain PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"system_message\", \"context\", \"question\", \"persona\"],\n",
    "    template=(\n",
    "        \"{system_message}\\n\\n\"\n",
    "        \"[Context to use for answer]\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"[User's Question]\\n\"\n",
    "        \"{question}\\n\\n\"\n",
    "        \"Answer as {persona}:\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f22cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compose the runnable pipeline\n",
    "llm_chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Run chain & print output\n",
    "result = llm_chain.invoke({\n",
    "    \"system_message\": system_message,\n",
    "    \"context\": context,\n",
    "    \"question\": user_question,\n",
    "    \"persona\": persona.title()\n",
    "})\n",
    "print(f\"{persona.title()} bot:\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5fe80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46534669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_130124\\2852306224.py:26: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: Title: Nepal Protest Live Updates: Army takes over as Nepal President, … Body: 2 days ago · Nepal Protest News Live: As Army takes over Nepal after violent protests, what is next for the country? Link: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "\n",
      "Scraped Article Content (first 5 paragraphs):\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n"
     ]
    }
   ],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        paras = [p.get_text() for p in soup.find_all('p')]\n",
    "        # Return first 5 non-empty paragraphs joined\n",
    "        content = '\\n\\n'.join([para for para in paras if para.strip()][:5])\n",
    "        # Heuristically check for CDN/ref error content\n",
    "        if (\"Reference #\" in content) or (\"edgesuite.net\" in content):\n",
    "            return \"Error: Hit a CDN/protection or error page. Try another link.\"\n",
    "        return content if content.strip() else \"No article paragraphs found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Could not fetch: {e}\"\n",
    "\n",
    "def retrieve_web_results(query, max_results=1):\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        if not results:\n",
    "            print(\"No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "        return results  # <-- return the dicts, not formatted strings!\n",
    "\n",
    "# Example usage\n",
    "query = \"What is Nepal News Today?\"\n",
    "results = retrieve_web_results(query, max_results=1)\n",
    "if results and results[0].get(\"href\"):\n",
    "    url = results[0][\"href\"]\n",
    "    article_text = fetch_article_text(url)\n",
    "    print(f\"\\nScraped Article Content (first 5 paragraphs):\\n{article_text}\")\n",
    "else:\n",
    "    print(\"No URL to fetch article content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4b4114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_130124\\3401872565.py:37: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: Title: Nepal Protest Live Updates: Army takes over as Nepal President, … Body: 2 days ago · Nepal Protest News Live: As Army takes over Nepal after violent protests, what is next for the country? Link: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     72\u001b[39m prompt = PromptTemplate(\n\u001b[32m     73\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33msrk_description\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     74\u001b[39m     template=prompt_template,\n\u001b[32m     75\u001b[39m )\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 4. LLM chain assembly (assuming you set up llm with HuggingFacePipeline)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m llm_chain = prompt | \u001b[43mllm\u001b[49m | StrOutputParser()\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# 5. Prepare inputs and run\u001b[39;00m\n\u001b[32m     81\u001b[39m inputs = {\n\u001b[32m     82\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msrk_description\u001b[39m\u001b[33m\"\u001b[39m: srk_persona,\n\u001b[32m     83\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: article_text,\n\u001b[32m     84\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: query,\n\u001b[32m     85\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. Persona Description (Shah Rukh Khan)\n",
    "srk_persona = (\n",
    "    \"You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. \"\n",
    "    \"Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"\n",
    "    \"\\\"Don ko pakadna mushkil hi nahin, namumkin hai!\\\" or \\\"Picture abhi baaki hai mere dost!\\\". \"\n",
    "    \"Always answer in this persona, with warmth, respect for fans, and a playful tone. \"\n",
    "    \"If you don't know the answer, say so with characteristic style.\"\n",
    ")\n",
    "# ------------------------------------------\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        paras = [p.get_text() for p in soup.find_all('p')]\n",
    "        content = '\\n\\n'.join([para for para in paras if para.strip()][:5])\n",
    "        if (\"Reference #\" in content) or (\"edgesuite.net\" in content):\n",
    "            return \"Error: Hit a CDN/protection or error page. Try another link.\"\n",
    "        return content if content.strip() else \"No article paragraphs found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Could not fetch: {e}\"\n",
    "\n",
    "def retrieve_web_results(query, max_results=1):\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        if not results:\n",
    "            print(\"No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "        return results\n",
    "\n",
    "# 2. Retrieve news and context\n",
    "query = \"What is Nepal News Today?\"\n",
    "results = retrieve_web_results(query, max_results=1)\n",
    "\n",
    "if results and results[0].get(\"href\"):\n",
    "    url = results[0][\"href\"]\n",
    "    article_text = fetch_article_text(url)\n",
    "else:\n",
    "    article_text = \"No article found.\"\n",
    "\n",
    "# 3. Build the prompt and chain (Zephyr/Llama3 format, Shah Rukh persona in <|system|>)\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "{srk_description}\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"srk_description\", \"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# 4. LLM chain assembly (assuming you set up llm with HuggingFacePipeline)\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 5. Prepare inputs and run\n",
    "inputs = {\n",
    "    \"srk_description\": srk_persona,\n",
    "    \"context\": article_text,\n",
    "    \"question\": query,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da81b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = llm_chain.invoke(inputs)\n",
    "print(f\"Shahrukh Khan bot:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5797afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Performing DuckDuckGo search for: 'What is Nepal News Today?' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_130124\\3850074517.py:31: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Result 1: Title: Nepal Protest Live Updates: Army takes over as Nepal President, … Body: 2 days ago · Nepal Protest News Live: As Army takes over Nepal after violent protests, what is next for the country? Link: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] Attempting to fetch article: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] First 5 paragraphs from article:\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "\n",
      "\n",
      "[DEBUG] Using article_text as context for LLM:\n",
      "---\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "---\n",
      "\n",
      "[DEBUG] Loading model: meta-llama/Llama-3.2-1B on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Final input passed to LLM (truncated):\n",
      "---\n",
      "\n",
      "<|system|>\n",
      "You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"Don ko pakadna mushkil hi nahin, namumkin hai!\" or \"Picture abhi baaki hai mere dost!\". Always answer in this persona, with warmth, respect for fans, and a playful tone. If you don't know the answer, say so with characteristic style.\n",
      "Answer the question based on your knowledge. Use the following context to help:\n",
      "\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been kil...\n",
      "---\n",
      "\n",
      "\n",
      "[DEBUG] Prompt actually passed to LLM (first 1000 chars):\n",
      "\n",
      "\n",
      "<|system|>\n",
      "You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"Don ko pakadna mushkil hi nahin, namumkin hai!\" or \"Picture abhi baaki hai mere dost!\". Always answer in this persona, with warmth, respect for fans, and a playful tone. If you don't know the answer, say so with characteristic style.\n",
      "Answer the question based on your knowledge. Use the following context to help:\n",
      "\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been kil ...\n",
      "\n",
      "\n",
      "Shahrukh Khan bot:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline  # Use langchain_huggingface for newer LangChain versions\n",
    "import torch\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG: Change model path and device as needed\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_NEW_TOKENS = 1000\n",
    "# ----------------------------\n",
    "\n",
    "# 1. Persona Description\n",
    "SRK_PERSONA = (\n",
    "    \"You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. \"\n",
    "    \"Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"\n",
    "    \"\\\"Don ko pakadna mushkil hi nahin, namumkin hai!\\\" or \\\"Picture abhi baaki hai mere dost!\\\". \"\n",
    "    \"Always answer in this persona, with warmth, respect for fans, and a playful tone. \"\n",
    "    \"If you don't know the answer, say so with characteristic style.\"\n",
    ")\n",
    "\n",
    "# 2. Web Search & Scraping\n",
    "def retrieve_web_results(query, max_results=1):\n",
    "    print(f\"[DEBUG] Performing DuckDuckGo search for: '{query}' ...\")\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        if not results:\n",
    "            print(\"[ERROR] No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"[DEBUG] Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "        return results\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    print(f\"[DEBUG] Attempting to fetch article: {url}\")\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        paras = [p.get_text() for p in soup.find_all('p')]\n",
    "        content = '\\n\\n'.join([para for para in paras if para.strip()][:5])\n",
    "        if (\"Reference #\" in content) or (\"edgesuite.net\" in content):\n",
    "            print(\"[WARNING] Hit a CDN/protection error page.\")\n",
    "            return \"Error: Hit a CDN/protection or error page. Try another link.\"\n",
    "        print(f\"[DEBUG] First 5 paragraphs from article:\\n{content}\\n\")\n",
    "        return content if content.strip() else \"No article paragraphs found.\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception during article fetch: {e}\")\n",
    "        return f\"Could not fetch: {e}\"\n",
    "\n",
    "# 3. Model/Pipeline Setup\n",
    "def setup_llm(model_name=MODEL_NAME, device=DEVICE):\n",
    "    print(f\"[DEBUG] Loading model: {model_name} on device: {device}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device)\n",
    "    text_gen = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "    )\n",
    "    return HuggingFacePipeline(pipeline=text_gen), tokenizer\n",
    "\n",
    "# 4. Prompt Template (Llama3/Zephyr-style)\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "{srk_description}\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    # ---- Begin pipeline ----\n",
    "\n",
    "    # [STEP 1] Get user query\n",
    "    user_question = \"What is Nepal News Today?\"\n",
    "\n",
    "    # [STEP 2] Retrieve Web Context\n",
    "    results = retrieve_web_results(user_question, max_results=1)\n",
    "    if results and results[0].get(\"href\"):\n",
    "        url = results[0][\"href\"]\n",
    "        article_text = fetch_article_text(url)\n",
    "    else:\n",
    "        url = None\n",
    "        article_text = \"No article found.\"\n",
    "\n",
    "    print(f\"\\n[DEBUG] Using article_text as context for LLM:\\n---\\n{article_text}\\n---\\n\")\n",
    "\n",
    "    # [STEP 3] Instantiate LLM\n",
    "    llm, tokenizer = setup_llm()\n",
    "\n",
    "    # [STEP 4] Prepare prompt via LangChain\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"srk_description\", \"context\", \"question\"],\n",
    "        template=PROMPT_TEMPLATE,\n",
    "    )\n",
    "\n",
    "    llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    inputs = {\n",
    "        \"srk_description\": SRK_PERSONA,\n",
    "        \"context\": article_text,\n",
    "        \"question\": user_question,\n",
    "    }\n",
    "\n",
    "    # [STEP 5] Print model input string (for debugging!)\n",
    "    str_prompt = PROMPT_TEMPLATE.format(\n",
    "        srk_description=SRK_PERSONA,\n",
    "        context=article_text,\n",
    "        question=user_question,\n",
    "    )\n",
    "    print(f\"[DEBUG] Final input passed to LLM (truncated):\\n---\\n{str_prompt[:1000]}...\\n---\\n\")  # Print first 1k chars\n",
    "\n",
    "    # [STEP 6] Inference\n",
    "    result = llm_chain.invoke(inputs)\n",
    "\n",
    "    print(\"\\n[DEBUG] Prompt actually passed to LLM (first 1000 chars):\\n\")\n",
    "    print(prompt.template.format(\n",
    "        srk_description=SRK_PERSONA,\n",
    "        context=article_text,\n",
    "        question=user_question\n",
    "    )[:1000], \"...\\n\")\n",
    "\n",
    "    print(f\"\\nShahrukh Khan bot:\\n{result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b69972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Performing DuckDuckGo search for: 'What is Nepal News Today?' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_130124\\1650231500.py:29: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Result 1: Title: Nepal Protest Live Updates: Army takes over as Nepal President, … Body: 2 days ago · Nepal Protest News Live: As Army takes over Nepal after violent protests, what is next for the country? Link: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] Attempting to fetch article: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] First 5 paragraphs from article:\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "\n",
      "\n",
      "[DEBUG] Using article_text as context for LLM:\n",
      "---\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "---\n",
      "\n",
      "[DEBUG] Loading model: meta-llama/Llama-3.2-1B on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Final Prompt Sent to LLM:\n",
      "<|system|>\n",
      "You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"Don ko pakadna mushkil hi nahin, namumkin hai!\" or \"Picture abhi baaki hai mere dost!\". Always answer in this persona, with warmth, respect for fans, and a playful tone. If you don't know the answer, say so with characteristic style.\n",
      "Answer the question based on your knowledge. Use the following context to help:\n",
      "\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been kill...\n",
      "\n",
      "\n",
      "Shahrukh Khan bot:\n",
      "\n",
      "Assistant Editor\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline  # Use langchain_huggingface for new versions (pip install -U langchain-huggingface)\n",
    "import torch\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG: Change model path and device as needed\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_NEW_TOKENS = 1000\n",
    "# ----------------------------\n",
    "\n",
    "# 1. Persona Description\n",
    "SRK_PERSONA = (\n",
    "    \"You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. \"\n",
    "    \"Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"\n",
    "    \"\\\"Don ko pakadna mushkil hi nahin, namumkin hai!\\\" or \\\"Picture abhi baaki hai mere dost!\\\". \"\n",
    "    \"Always answer in this persona, with warmth, respect for fans, and a playful tone. \"\n",
    "    \"If you don't know the answer, say so with characteristic style.\"\n",
    ")\n",
    "\n",
    "# 2. Web Search & Scraping\n",
    "def retrieve_web_results(query, max_results=1):\n",
    "    print(f\"[DEBUG] Performing DuckDuckGo search for: '{query}' ...\")\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        if not results:\n",
    "            print(\"[ERROR] No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"[DEBUG] Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "        return results\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    print(f\"[DEBUG] Attempting to fetch article: {url}\")\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        paras = [p.get_text() for p in soup.find_all('p')]\n",
    "        content = '\\n\\n'.join([para for para in paras if para.strip()][:5])\n",
    "        if (\"Reference #\" in content) or (\"edgesuite.net\" in content):\n",
    "            print(\"[WARNING] Hit a CDN/protection error page.\")\n",
    "            return \"Error: Hit a CDN/protection or error page. Try another link.\"\n",
    "        print(f\"[DEBUG] First 5 paragraphs from article:\\n{content}\\n\")\n",
    "        return content if content.strip() else \"No article paragraphs found.\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception during article fetch: {e}\")\n",
    "        return f\"Could not fetch: {e}\"\n",
    "\n",
    "# 3. Model/Pipeline Setup\n",
    "def setup_llm(model_name=MODEL_NAME, device=DEVICE):\n",
    "    print(f\"[DEBUG] Loading model: {model_name} on device: {device}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device)\n",
    "    text_gen = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "    )\n",
    "    return HuggingFacePipeline(pipeline=text_gen), tokenizer\n",
    "\n",
    "# 4. Prompt Template (Llama3/Zephyr-style)\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "{srk_description}\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    # [STEP 1] Get user query\n",
    "    user_question = \"What is Nepal News Today?\"\n",
    "\n",
    "    # [STEP 2] Retrieve Web Context\n",
    "    results = retrieve_web_results(user_question, max_results=1)\n",
    "    if results and results[0].get(\"href\"):\n",
    "        url = results[0][\"href\"]\n",
    "        article_text = fetch_article_text(url)\n",
    "    else:\n",
    "        url = None\n",
    "        article_text = (\n",
    "            \"No article found. But in my style: Picture abhi baaki hai mere dost! Even Don can't find all the news!\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[DEBUG] Using article_text as context for LLM:\\n---\\n{article_text}\\n---\\n\")\n",
    "\n",
    "    # [STEP 3] Instantiate LLM\n",
    "    llm, tokenizer = setup_llm()\n",
    "\n",
    "    # [STEP 4] Direct plain-string prompt, NO LangChain needed\n",
    "    prompt_str = (\n",
    "        f\"<|system|>\\n{SRK_PERSONA}\\nAnswer the question based on your knowledge. Use the following context to help:\\n\\n\"\n",
    "        f\"{article_text}\\n\\n</s>\\n<|user|>\\n{user_question}\\n</s>\\n<|assistant|>\\n\"\n",
    "    )\n",
    "    print(f\"[DEBUG] Final Prompt Sent to LLM:\\n{prompt_str[:1000]}...\\n\")\n",
    "\n",
    "    # [STEP 5] LLM Inference, print response\n",
    "    result = llm(prompt_str)\n",
    "    print(\"\\nShahrukh Khan bot:\\n\")\n",
    "    if isinstance(result, list):\n",
    "        print(result[0][\"generated_text\"] if \"generated_text\" in result[0] else str(result[0]))\n",
    "    else:\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87932ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Performing DuckDuckGo search for: 'What is Nepal News Today?' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_130124\\3056920477.py:27: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Result 1: Title: Nepal Protest Live Updates: Army takes over as Nepal President, … Body: 2 days ago · Nepal Protest News Live: As Army takes over Nepal after violent protests, what is next for the country? Link: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] Attempting to fetch article: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] First 5 paragraphs from article:\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "\n",
      "\n",
      "[DEBUG] Using article_text as context for LLM:\n",
      "---\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "---\n",
      "\n",
      "[DEBUG] Loading model: microsoft/phi-3-mini-4k-instruct on device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbefd74c80af43bfb7147ffc9b775dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4a96d19c914dd3b45f5eb37c1c9091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac4cde896e34b6ab2748bd41505151b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236349267b9a4b5abf0df662fa6391dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2afe5f9516f41ef830428a028c5d4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9f75b568c84bb5ac3067931de9feca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f67fdfdca3645e6b99d23d67150d638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b9e1f332d44a9584f04c4af88e9301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac6ef32aa2546c2a5017486d03aba51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f422ba07cd346f6ab9c68159b5a2536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a060b7af35640adaaf3c95b1f417c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c2ee99cea645d7834bf42108f1ef62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8ce820>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf3f0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8ce040>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cdf60>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfb60>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfbd0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfc40>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf460>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf3f0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfcb0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8ce7b0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf8c0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cdf60>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfbd0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8ce820>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf460>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf3f0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c837770>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cf8c0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfb60>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cdf60>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8373f0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8cfaf0>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\PROJECTS\\RAG\\ddgo\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:154: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2353c8ce040>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline  # pip install -U langchain-huggingface\n",
    "import torch\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG: Change model for phi-3, llama-3, or any GPT/chat-model\n",
    "MODEL_NAME = \"microsoft/phi-3-mini-4k-instruct\"  # swap to \"meta-llama/Llama-3.2-1B\" if needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_NEW_TOKENS = 1000\n",
    "# ----------------------------\n",
    "\n",
    "SRK_PERSONA = (\n",
    "    \"You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. \"\n",
    "    \"Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"\n",
    "    \"\\\"Don ko pakadna mushkil hi nahin, namumkin hai!\\\" or \\\"Picture abhi baaki hai mere dost!\\\". \"\n",
    "    \"Always answer in this persona, with warmth, respect for fans, and a playful tone. \"\n",
    "    \"If you don't know the answer, say so with characteristic style.\"\n",
    ")\n",
    "\n",
    "def retrieve_web_results(query, max_results=1):\n",
    "    print(f\"[DEBUG] Performing DuckDuckGo search for: '{query}' ...\")\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        if not results:\n",
    "            print(\"[ERROR] No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"[DEBUG] Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "        return results\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    print(f\"[DEBUG] Attempting to fetch article: {url}\")\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        paras = [p.get_text() for p in soup.find_all('p')]\n",
    "        content = '\\n\\n'.join([para for para in paras if para.strip()][:5])\n",
    "        if (\"Reference #\" in content) or (\"edgesuite.net\" in content):\n",
    "            print(\"[WARNING] Hit a CDN/protection error page.\")\n",
    "            return \"Error: Hit a CDN/protection or error page. Try another link.\"\n",
    "        print(f\"[DEBUG] First 5 paragraphs from article:\\n{content}\\n\")\n",
    "        return content if content.strip() else \"No article paragraphs found.\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception during article fetch: {e}\")\n",
    "        return f\"Could not fetch: {e}\"\n",
    "\n",
    "def setup_llm(model_name=MODEL_NAME, device=DEVICE):\n",
    "    print(f\"[DEBUG] Loading model: {model_name} on device: {device}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device, trust_remote_code=True)\n",
    "    text_gen = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "    )\n",
    "    return HuggingFacePipeline(pipeline=text_gen), tokenizer\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "{srk_description}\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    user_question = \"What is Nepal News Today?\"\n",
    "    results = retrieve_web_results(user_question, max_results=1)\n",
    "    if results and results[0].get(\"href\"):\n",
    "        url = results[0][\"href\"]\n",
    "        article_text = fetch_article_text(url)\n",
    "    else:\n",
    "        url = None\n",
    "        article_text = (\n",
    "            \"No article found. But in my style: Picture abhi baaki hai mere dost! Even Don can't find all the news!\"\n",
    "        )\n",
    "    print(f\"\\n[DEBUG] Using article_text as context for LLM:\\n---\\n{article_text}\\n---\\n\")\n",
    "\n",
    "    llm, tokenizer = setup_llm()\n",
    "\n",
    "    prompt_str = (\n",
    "        f\"<|system|>\\n{SRK_PERSONA}\\nAnswer the question based on your knowledge. Use the following context to help:\\n\\n\"\n",
    "        f\"{article_text}\\n\\n</s>\\n<|user|>\\n{user_question}\\n</s>\\n<|assistant|>\\n\"\n",
    "    )\n",
    "    print(f\"[DEBUG] Final Prompt Sent to LLM:\\n{prompt_str[:1000]}...\\n\")\n",
    "\n",
    "    result = llm(prompt_str)\n",
    "    print(\"\\nShahrukh Khan bot:\\n\")\n",
    "    if isinstance(result, list):\n",
    "        print(result[0][\"generated_text\"] if \"generated_text\" in result[0] else str(result[0]))\n",
    "    else:\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a89aee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Performing DuckDuckGo search for: 'What is Nepal News Today?' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_127736\\360590511.py:27: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Result 1: Title: Nepal Protest Live Updates: Army takes over as Nepal President, … Body: 2 days ago · Nepal Protest News Live: As Army takes over Nepal after violent protests, what is next for the country? Link: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] Attempting to fetch article: https://www.financialexpress.com/world-news/nepal-protest-live-updates-army-takes-over-as-nepal-president-pm-resign-mea-sets-up-helpline/3972552/\n",
      "[DEBUG] First 5 paragraphs from article:\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "\n",
      "\n",
      "[DEBUG] Using article_text as context for LLM:\n",
      "---\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been killed in the protest, and 40 have been arrested. A total of 7,557 prisoners reportedly escaped from various jails across Nepal. The toppling of the government is just like what happened in Bangladesh and Sri Lanka.\n",
      "\n",
      "Day 2 of the Gen-Z protests saw the resignation of Prime Minister KP Sharma Oli, hours after he appealed for calm and called an all-party meet to discuss the situation. President Ram Chandra Poudel accepted his resignation amid political unrest over “corruption”. \n",
      "\n",
      "Protesters set fire to anything in their path, including ministers’ private residences, the Supreme Court, the entrance to Parliament, and the ruling Congress party’s office. The violence intensified to such an extent that the Army was deployed, airports were shut, and several ministers, both current and former, had to be rescued. Videos showing the Finance Minister being chased, beaten, and kicked by mobs flooded social media, highlighting the extent of the chaos.\n",
      "\n",
      "PM Modi is quite disturbed by the chaos in Nepal and has appealed for peace. \n",
      "\n",
      "“After returning from the day’s tour today, there was a detailed discussion about the events in Nepal at the meeting of the Cabinet Committee on Security Affairs. The violence that has occurred in Nepal is heart-wrenching,” PM Modi said. \n",
      "---\n",
      "\n",
      "[DEBUG] Loading model: meta-llama/Llama-3.2-1B on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\lordb\\AppData\\Local\\Temp\\ipykernel_127736\\360590511.py:109: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = llm(prompt_str)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Final Prompt Sent to LLM:\n",
      "<|system|>\n",
      "You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"Don ko pakadna mushkil hi nahin, namumkin hai!\" or \"Picture abhi baaki hai mere dost!\". Always answer in this persona, with warmth, respect for fans, and a playful tone. If you don't know the answer, say so with characteristic style.\n",
      "Answer the question based on your knowledge. Use the following context to help:\n",
      "\n",
      "Nepal Gen Z Protest, PM KP Sharma Oli Resignation Highlights: What started as a Gen-Z protest against the ban on 26 social media platforms, including Facebook, Instagram, WhatsApp, X and LinkedIn, turned into something very big that saw the ouster of the Oli government. Although the ban was lifted late at night on Day 1 of the protest, and a curfew was imposed to bring the situation under control, few anticipated the scale of unrest that would follow. 19 people have been kill...\n",
      "\n",
      "\n",
      "Shahrukh Khan bot:\n",
      "\n",
      "Assistant Editor\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline  # pip install -U langchain-huggingface\n",
    "import torch\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG: Change model for phi-3, llama-3, or any GPT/chat-model\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"     # swap to \"meta-llama/Llama-3.2-1B\" if needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_NEW_TOKENS = 1000\n",
    "# ----------------------------\n",
    "\n",
    "SRK_PERSONA = (\n",
    "    \"You are Shah Rukh Khan, the legendary Bollywood superstar, beloved as 'King Khan'. \"\n",
    "    \"Your speaking style is witty, charming, and full of heart—you're quick with humor and iconic movie lines like \"\n",
    "    \"\\\"Don ko pakadna mushkil hi nahin, namumkin hai!\\\" or \\\"Picture abhi baaki hai mere dost!\\\". \"\n",
    "    \"Always answer in this persona, with warmth, respect for fans, and a playful tone. \"\n",
    "    \"If you don't know the answer, say so with characteristic style.\"\n",
    ")\n",
    "\n",
    "def retrieve_web_results(query, max_results=1):\n",
    "    print(f\"[DEBUG] Performing DuckDuckGo search for: '{query}' ...\")\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=max_results)\n",
    "        if not results:\n",
    "            print(\"[ERROR] No search results returned from DuckDuckGo.\")\n",
    "            return []\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"[DEBUG] Result {i+1}: Title: {r['title']} Body: {r['body']} Link: {r['href']}\")\n",
    "        return results\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    print(f\"[DEBUG] Attempting to fetch article: {url}\")\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        paras = [p.get_text() for p in soup.find_all('p')]\n",
    "        content = '\\n\\n'.join([para for para in paras if para.strip()][:5])\n",
    "        if (\"Reference #\" in content) or (\"edgesuite.net\" in content):\n",
    "            print(\"[WARNING] Hit a CDN/protection error page.\")\n",
    "            return \"Error: Hit a CDN/protection or error page. Try another link.\"\n",
    "        print(f\"[DEBUG] First 5 paragraphs from article:\\n{content}\\n\")\n",
    "        return content if content.strip() else \"No article paragraphs found.\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception during article fetch: {e}\")\n",
    "        return f\"Could not fetch: {e}\"\n",
    "\n",
    "def setup_llm(model_name=MODEL_NAME, device=DEVICE):\n",
    "    print(f\"[DEBUG] Loading model: {model_name} on device: {device}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device, trust_remote_code=True)\n",
    "    text_gen = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "    )\n",
    "    return HuggingFacePipeline(pipeline=text_gen), tokenizer\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "{srk_description}\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    user_question = \"What is Nepal News Today?\"\n",
    "    results = retrieve_web_results(user_question, max_results=1)\n",
    "    if results and results[0].get(\"href\"):\n",
    "        url = results[0][\"href\"]\n",
    "        article_text = fetch_article_text(url)\n",
    "    else:\n",
    "        url = None\n",
    "        article_text = (\n",
    "            \"No article found. But in my style: Picture abhi baaki hai mere dost! Even Don can't find all the news!\"\n",
    "        )\n",
    "    print(f\"\\n[DEBUG] Using article_text as context for LLM:\\n---\\n{article_text}\\n---\\n\")\n",
    "\n",
    "    llm, tokenizer = setup_llm()\n",
    "\n",
    "    prompt_str = (\n",
    "        f\"<|system|>\\n{SRK_PERSONA}\\nAnswer the question based on your knowledge. Use the following context to help:\\n\\n\"\n",
    "        f\"{article_text}\\n\\n</s>\\n<|user|>\\n{user_question}\\n</s>\\n<|assistant|>\\n\"\n",
    "    )\n",
    "    print(f\"[DEBUG] Final Prompt Sent to LLM:\\n{prompt_str[:1000]}...\\n\")\n",
    "\n",
    "    result = llm(prompt_str)\n",
    "    print(\"\\nShahrukh Khan bot:\\n\")\n",
    "    if isinstance(result, list):\n",
    "        print(result[0][\"generated_text\"] if \"generated_text\" in result[0] else str(result[0]))\n",
    "    else:\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a511d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
